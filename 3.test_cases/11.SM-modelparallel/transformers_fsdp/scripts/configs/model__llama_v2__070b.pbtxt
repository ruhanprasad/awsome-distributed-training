name: "llama2-070b"
rubik_job {
  fsdp {
    sharding_strategy: HYBRID_SHARD
    sharded_data_parallel_degree: 128
  }
  model {
    transformer_model {
      named_model: LLAMA_V2_070B
    }
  }
}
runtime {
  nodes {
    num_nodes: 16
  }
}
